#!/usr/bin/env python3
"""
vLLM Scheduler æ€§èƒ½å»ºæ¨¡
åŸºäºååé¥±å’Œç†è®ºçš„ç‰©ç†å¯å‘æ¨¡å‹

æ¨¡å‹å½¢å¼:
Thr(B,S) = P_max * (1 - exp(-k_B * B)) * (1 - exp(-k_S * S))
Work(B,S) = w_0 + w_1 * S
T(B,S) = Ï„_0 + Work(B,S) / Thr(B,S) + Ï„_B * B + Ï„_S * S

å…¶ä¸­:
- B: batch_size (è¯·æ±‚æ•°é‡)
- S: total_tokens (sum of chunk_sizes)
- T: model_run_duration_ms (å»¶è¿Ÿ)
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import warnings
from typing import Tuple, Dict, Optional, Union
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ThroughputSaturationModel:
    """åŸºäºååé¥±å’Œç†è®ºçš„æ€§èƒ½å»ºæ¨¡ç±»"""
    
    def __init__(self, verbose: bool = True):
        """
        åˆå§‹åŒ–æ¨¡å‹
        
        Args:
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        """
        self.verbose = verbose
        self.is_fitted = False
        self.params = None
        self.scales = None
        self.fit_metrics = None
        
        # å‚æ•°åç§°å’Œå«ä¹‰
        self.param_names = [
            'P_max', 'k_B', 'k_S', 'w_0', 'w_1', 'tau_0', 'tau_B', 'tau_S'
        ]
        self.param_descriptions = {
            'P_max': 'æœ€å¤§æœ‰æ•ˆååé‡ (tokens/ms)',
            'k_B': 'batchå¹¶è¡Œåº¦æ•æ„Ÿç³»æ•°',
            'k_S': 'tokenå¹¶è¡Œåº¦æ•æ„Ÿç³»æ•°', 
            'w_0': 'åŸºç¡€å·¥ä½œé‡å¸¸æ•°',
            'w_1': 'æ¯tokenå·¥ä½œé‡ç³»æ•°',
            'tau_0': 'åŸºç¡€å»¶è¿Ÿå¸¸æ•° (ms)',
            'tau_B': 'æ¯batché¢å¤–å»¶è¿Ÿ (ms/batch)',
            'tau_S': 'æ¯tokené¢å¤–å»¶è¿Ÿ (ms/token)'
        }
    
    @staticmethod
    def throughput(B: np.ndarray, S: np.ndarray, P_max: float, k_B: float, k_S: float) -> np.ndarray:
        """
        è®¡ç®—æœ‰æ•ˆååé‡
        
        Args:
            B: batch_sizeæ•°ç»„
            S: total_tokensæ•°ç»„
            P_max: æœ€å¤§ååé‡
            k_B: batchæ•æ„Ÿç³»æ•°
            k_S: tokenæ•æ„Ÿç³»æ•°
            
        Returns:
            æœ‰æ•ˆååé‡æ•°ç»„
        """
        return P_max * (1.0 - np.exp(-k_B * B)) * (1.0 - np.exp(-k_S * S))
    
    @staticmethod
    def workload(S: np.ndarray, w_0: float, w_1: float) -> np.ndarray:
        """
        è®¡ç®—å·¥ä½œé‡
        
        Args:
            S: total_tokensæ•°ç»„
            w_0: åŸºç¡€å·¥ä½œé‡
            w_1: æ¯tokenå·¥ä½œé‡
            
        Returns:
            å·¥ä½œé‡æ•°ç»„
        """
        return w_0 + w_1 * S
    
    @staticmethod
    def latency_model(X: Tuple[np.ndarray, np.ndarray], 
                     P_max: float, k_B: float, k_S: float, 
                     w_0: float, w_1: float, 
                     tau_0: float, tau_B: float, tau_S: float) -> np.ndarray:
        """
        å®Œæ•´çš„å»¶è¿Ÿæ¨¡å‹
        
        Args:
            X: (B, S) å…ƒç»„ï¼Œå…¶ä¸­Bä¸ºbatch_sizeæ•°ç»„ï¼ŒSä¸ºtotal_tokensæ•°ç»„
            P_max, k_B, k_S: ååé‡å‚æ•°
            w_0, w_1: å·¥ä½œé‡å‚æ•°
            tau_0, tau_B, tau_S: çº¿æ€§å¼€é”€å‚æ•°
            
        Returns:
            é¢„æµ‹å»¶è¿Ÿæ•°ç»„
        """
        B, S = X
        
        # è®¡ç®—æœ‰æ•ˆååé‡
        thr = ThroughputSaturationModel.throughput(B, S, P_max, k_B, k_S)
        
        # è®¡ç®—å·¥ä½œé‡
        work = ThroughputSaturationModel.workload(S, w_0, w_1)
        
        # é¿å…é™¤é›¶
        thr = np.maximum(thr, 1e-9)
        
        # è®¡ç®—æ€»å»¶è¿Ÿ
        latency = tau_0 + work / thr + tau_B * B + tau_S * S
        
        return latency
    
    def _extract_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        ä»DataFrameä¸­æå–ç‰¹å¾
        
        Args:
            df: åŒ…å«scheduler profilingæ•°æ®çš„DataFrame
            
        Returns:
            (B, S, T) å…ƒç»„ï¼Œåˆ†åˆ«ä¸ºbatch_sizeã€total_tokensã€å»¶è¿Ÿ
        """
        def _compute_batch_size(chunk_sizes):
            """è®¡ç®—batch size"""
            if isinstance(chunk_sizes, list):
                return len(chunk_sizes)
            return np.nan
            
        def _compute_total_tokens(chunk_sizes):
            """è®¡ç®—æ€»tokenæ•°"""
            if isinstance(chunk_sizes, list) and len(chunk_sizes) > 0:
                return float(sum(chunk_sizes))
            if isinstance(chunk_sizes, (int, float)):
                return float(chunk_sizes)
            return np.nan
        
        # æå–ç‰¹å¾
        B = df['chunk_sizes'].apply(_compute_batch_size).to_numpy(dtype=float)
        S = df['chunk_sizes'].apply(_compute_total_tokens).to_numpy(dtype=float)
        T = df['model_run_duration_ms'].to_numpy(dtype=float)
        
        return B, S, T
    
    def _preprocess_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        æ•°æ®é¢„å¤„ç†ï¼šæå–ç‰¹å¾ã€è¿‡æ»¤å¼‚å¸¸å€¼ã€æ£€æŸ¥æœ‰æ•ˆæ€§
        
        Args:
            df: åŸå§‹æ•°æ®DataFrame
            
        Returns:
            å¤„ç†åçš„ (B, S, T) å…ƒç»„
        """
        if self.verbose:
            logger.info("å¼€å§‹æ•°æ®é¢„å¤„ç†...")
            
        # æå–ç‰¹å¾
        B, S, T = self._extract_features(df)
        
        # åˆå§‹æ•°æ®é‡
        initial_count = len(T)
        
        # åˆ›å»ºæœ‰æ•ˆæ€§æ©ç 
        valid_mask = (
            np.isfinite(B) & np.isfinite(S) & np.isfinite(T) &
            (B > 0) & (S > 0) & (T > 0) &
            (T < 200)  # è¿‡æ»¤è¿‡é•¿å»¶è¿Ÿ
        )
        
        # åº”ç”¨æ©ç 
        B, S, T = B[valid_mask], S[valid_mask], T[valid_mask]
        
        if self.verbose:
            logger.info(f"æ•°æ®è¿‡æ»¤: {initial_count} -> {len(T)} æ ·æœ¬")
            logger.info(f"Batch Size èŒƒå›´: [{B.min():.1f}, {B.max():.1f}]")
            logger.info(f"Total Tokens èŒƒå›´: [{S.min():.1f}, {S.max():.1f}]")
            logger.info(f"å»¶è¿ŸèŒƒå›´: [{T.min():.2f}, {T.max():.2f}] ms")
        
        if len(T) < 20:
            raise ValueError(f"æœ‰æ•ˆæ ·æœ¬æ•°è¿‡å°‘: {len(T)}ï¼Œå»ºè®®è‡³å°‘20ä¸ªæ ·æœ¬")
            
        return B, S, T
    
    def _normalize_features(self, B: np.ndarray, S: np.ndarray) -> Tuple[np.ndarray, np.ndarray, Tuple[float, float]]:
        """
        ç‰¹å¾å½’ä¸€åŒ–ï¼Œä½¿ç”¨ä¸­ä½æ•°ç¼©æ”¾
        
        Args:
            B: batch_sizeæ•°ç»„
            S: total_tokensæ•°ç»„
            
        Returns:
            (B_norm, S_norm, scales) å…ƒç»„
        """
        B_median = np.median(B)
        S_median = np.median(S)
        
        # é¿å…é™¤é›¶
        B_scale = max(B_median, 1.0)
        S_scale = max(S_median, 1.0)
        
        B_norm = B / B_scale
        S_norm = S / S_scale
        
        scales = (B_scale, S_scale)
        
        if self.verbose:
            logger.info(f"ç‰¹å¾å½’ä¸€åŒ–: B_scale={B_scale:.2f}, S_scale={S_scale:.2f}")
            
        return B_norm, S_norm, scales
    
    def _initialize_parameters(self, B: np.ndarray, S: np.ndarray, T: np.ndarray) -> Tuple[list, list, list]:
        """
        å‚æ•°åˆå§‹åŒ–
        
        Args:
            B, S, T: å½’ä¸€åŒ–åçš„ç‰¹å¾å’Œç›®æ ‡
            
        Returns:
            (åˆå§‹å€¼, ä¸‹ç•Œ, ä¸Šç•Œ) å…ƒç»„
        """
        # ä¼°è®¡å³°å€¼ååé‡
        throughput_estimates = S / np.maximum(T, 1e-6)
        P_max_init = max(np.percentile(throughput_estimates, 95), 1e-3)
        
        # çº¿æ€§æ‹Ÿåˆä¼°è®¡w_1
        try:
            w_1_init = max(np.polyfit(S, T, 1)[0], 1e-9)
        except:
            w_1_init = 0.01
        
        # åˆå§‹å‚æ•°
        p0 = [
            P_max_init,     # P_max
            0.1,            # k_B
            0.01,           # k_S  
            0.1,            # w_0
            w_1_init,       # w_1
            np.min(T) * 0.5, # tau_0
            1e-3,           # tau_B
            1e-3            # tau_S
        ]
        
        # å‚æ•°ä¸‹ç•Œï¼ˆç‰©ç†åˆç†æ€§ï¼‰
        lower_bounds = [1e-6, 1e-6, 1e-6, 0.0, 1e-9, 0.0, 0.0, 0.0]
        
        # å‚æ•°ä¸Šç•Œï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
        upper_bounds = [100, 10.0, 10.0, 10.0, 1e2, 1e3, 1e1, 1e1]
        
        if self.verbose:
            logger.info(f"å‚æ•°åˆå§‹åŒ–: P_max={P_max_init:.3f}, w_1={w_1_init:.6f}")
            
        return p0, lower_bounds, upper_bounds
    
    def fit(self, df: pd.DataFrame) -> 'ThroughputSaturationModel':
        """
        æ‹Ÿåˆæ¨¡å‹
        
        Args:
            df: åŒ…å«scheduler profilingæ•°æ®çš„DataFrame
            
        Returns:
            self (æ”¯æŒé“¾å¼è°ƒç”¨)
        """
        if self.verbose:
            logger.info("å¼€å§‹æ¨¡å‹æ‹Ÿåˆ...")
            
        # æ•°æ®é¢„å¤„ç†
        B, S, T = self._preprocess_data(df)
        
        # ç‰¹å¾å½’ä¸€åŒ–
        B_norm, S_norm, scales = self._normalize_features(B, S)
        self.scales = scales
        
        # å‚æ•°åˆå§‹åŒ–
        p0, lower_bounds, upper_bounds = self._initialize_parameters(B_norm, S_norm, T)
        
        # éçº¿æ€§æ‹Ÿåˆ
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                
                popt, pcov = curve_fit(
                    lambda X, *params: self.latency_model(X, *params),
                    xdata=(B_norm, S_norm),
                    ydata=T,
                    p0=p0,
                    bounds=(lower_bounds, upper_bounds),
                    maxfev=20000,
                    method='trf'  # Trust Region Reflectiveç®—æ³•ï¼Œå¯¹è¾¹ç•Œçº¦æŸå‹å¥½
                )
                
            self.params = popt
            self.param_cov = pcov
            self.is_fitted = True
            
            # è®¡ç®—æ‹Ÿåˆè´¨é‡æŒ‡æ ‡
            T_pred = self.latency_model((B_norm, S_norm), *popt)
            self.fit_metrics = {
                'r2': r2_score(T, T_pred),
                'rmse': np.sqrt(mean_squared_error(T, T_pred)),
                'mae': mean_absolute_error(T, T_pred),
                'n_samples': len(T)
            }
            
            if self.verbose:
                self._print_fit_results()
                
        except Exception as e:
            logger.error(f"æ‹Ÿåˆå¤±è´¥: {e}")
            raise
            
        return self
    
    def _print_fit_results(self):
        """æ‰“å°æ‹Ÿåˆç»“æœ"""
        logger.info("æ‹Ÿåˆå®Œæˆ!")
        logger.info(f"RÂ² = {self.fit_metrics['r2']:.4f}")
        logger.info(f"RMSE = {self.fit_metrics['rmse']:.3f} ms")
        logger.info(f"MAE = {self.fit_metrics['mae']:.3f} ms")
        logger.info(f"æ ·æœ¬æ•° = {self.fit_metrics['n_samples']}")
        
        logger.info("\næ‹Ÿåˆå‚æ•°:")
        for i, (name, desc) in enumerate(zip(self.param_names, self.param_descriptions.values())):
            logger.info(f"{name:8s} = {self.params[i]:10.6f}  # {desc}")
            
        # å‚æ•°æ ‡å‡†è¯¯å·®ï¼ˆå¦‚æœåæ–¹å·®çŸ©é˜µå¯ç”¨ï¼‰
        try:
            param_std = np.sqrt(np.diag(self.param_cov))
            logger.info("\nå‚æ•°æ ‡å‡†è¯¯å·®:")
            for i, name in enumerate(self.param_names):
                logger.info(f"{name:8s} Â± {param_std[i]:10.6f}")
        except:
            pass
    
    def predict(self, batch_size: Union[float, np.ndarray], 
                total_tokens: Union[float, np.ndarray]) -> Union[float, np.ndarray]:
        """
        é¢„æµ‹å»¶è¿Ÿ
        
        Args:
            batch_size: æ‰¹æ¬¡å¤§å°
            total_tokens: æ€»tokenæ•°
            
        Returns:
            é¢„æµ‹çš„å»¶è¿Ÿ (ms)
        """
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨ fit() æ–¹æ³•")
            
        # è½¬æ¢ä¸ºæ•°ç»„
        B = np.asarray(batch_size)
        S = np.asarray(total_tokens)
        
        # å½’ä¸€åŒ–
        B_scale, S_scale = self.scales
        B_norm = B / B_scale
        S_norm = S / S_scale
        
        # é¢„æµ‹
        latency = self.latency_model((B_norm, S_norm), *self.params)
        
        return latency
    
    def plot_contour(self, batch_range: Tuple[int, int] = (1, 64),
                    token_range: Tuple[int, int] = (1, 2048),
                    resolution: int = 50,
                    figsize: Tuple[int, int] = (12, 8),
                    save_path: Optional[str] = None) -> plt.Figure:
        """
        ç»˜åˆ¶å»¶è¿Ÿç­‰é«˜çº¿å›¾
        
        Args:
            batch_range: batch_sizeèŒƒå›´
            token_range: total_tokensèŒƒå›´  
            resolution: ç½‘æ ¼åˆ†è¾¨ç‡
            figsize: å›¾åƒå¤§å°
            save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            matplotlib Figureå¯¹è±¡
        """
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨ fit() æ–¹æ³•")
            
        # åˆ›å»ºç½‘æ ¼
        B_grid = np.linspace(batch_range[0], batch_range[1], resolution)
        S_grid = np.linspace(token_range[0], token_range[1], resolution)
        B_mesh, S_mesh = np.meshgrid(B_grid, S_grid)
        
        # é¢„æµ‹å»¶è¿Ÿ
        T_mesh = self.predict(B_mesh.flatten(), S_mesh.flatten()).reshape(B_mesh.shape)
        
        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=figsize)
        
        # å¡«å……ç­‰é«˜çº¿
        cs1 = ax.contourf(B_mesh, S_mesh, T_mesh, levels=20, cmap='viridis', alpha=0.8)
        cbar1 = plt.colorbar(cs1, ax=ax)
        cbar1.set_label('Model Run Latency (ms)', fontsize=12)
        
        # ç­‰é«˜çº¿
        cs2 = ax.contour(B_mesh, S_mesh, T_mesh, levels=10, colors='white', linewidths=1, alpha=0.7)
        ax.clabel(cs2, inline=True, fontsize=9, fmt='%1.0f ms')
        
        ax.set_xlabel('Batch Size', fontsize=12)
        ax.set_ylabel('Total Tokens', fontsize=12)
        ax.set_title('vLLM Model Run Latency Prediction\n(Throughput Saturation Model)', fontsize=14)
        ax.grid(True, linestyle='--', alpha=0.3)
        
        # æ·»åŠ æ¨¡å‹ä¿¡æ¯
        if self.fit_metrics:
            info_text = f"RÂ² = {self.fit_metrics['r2']:.3f}\nRMSE = {self.fit_metrics['rmse']:.1f} ms"
            ax.text(0.02, 0.98, info_text, transform=ax.transAxes, 
                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            if self.verbose:
                logger.info(f"Contour plot saved: {save_path}")
                
        return fig
    
    def plot_residuals(self, df: pd.DataFrame, figsize: Tuple[int, int] = (15, 5)) -> plt.Figure:
        """
        ç»˜åˆ¶æ®‹å·®åˆ†æå›¾
        
        Args:
            df: è®­ç»ƒæ•°æ®DataFrame
            figsize: å›¾åƒå¤§å°
            
        Returns:
            matplotlib Figureå¯¹è±¡
        """
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨ fit() æ–¹æ³•")
            
        # è·å–æ•°æ®
        B, S, T = self._preprocess_data(df)
        B_norm, S_norm, _ = self._normalize_features(B, S)
        
        # é¢„æµ‹å€¼
        T_pred = self.latency_model((B_norm, S_norm), *self.params)
        residuals = T - T_pred
        
        # ç»˜å›¾
        fig, axes = plt.subplots(1, 3, figsize=figsize)
        
        # é¢„æµ‹å€¼ vs çœŸå®å€¼
        axes[0].scatter(T_pred, T, alpha=0.6, s=20)
        axes[0].plot([T.min(), T.max()], [T.min(), T.max()], 'r--', lw=2)
        axes[0].set_xlabel('Predicted Latency (ms)')
        axes[0].set_ylabel('Actual Latency (ms)')
        axes[0].set_title('Predicted vs Actual')
        axes[0].grid(True, alpha=0.3)
        
        # æ®‹å·® vs é¢„æµ‹å€¼
        axes[1].scatter(T_pred, residuals, alpha=0.6, s=20)
        axes[1].axhline(y=0, color='r', linestyle='--', lw=2)
        axes[1].set_xlabel('Predicted Latency (ms)')
        axes[1].set_ylabel('Residuals (ms)')
        axes[1].set_title('Residuals vs Predicted')
        axes[1].grid(True, alpha=0.3)
        
        # æ®‹å·®ç›´æ–¹å›¾
        axes[2].hist(residuals, bins=30, alpha=0.7, edgecolor='black')
        axes[2].axvline(x=0, color='r', linestyle='--', lw=2)
        axes[2].set_xlabel('Residuals (ms)')
        axes[2].set_ylabel('Frequency')
        axes[2].set_title('Residuals Distribution')
        axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        return fig
    
    def get_model_summary(self) -> Dict:
        """
        è·å–æ¨¡å‹æ‘˜è¦ä¿¡æ¯
        
        Returns:
            åŒ…å«æ¨¡å‹å‚æ•°å’ŒæŒ‡æ ‡çš„å­—å…¸
        """
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨ fit() æ–¹æ³•")
            
        summary = {
            'parameters': dict(zip(self.param_names, self.params)),
            'metrics': self.fit_metrics,
            'scales': {'batch_scale': self.scales[0], 'token_scale': self.scales[1]}
        }
        
        return summary
    
    def save_model(self, filepath: str):
        """
        ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶
        
        Args:
            filepath: ä¿å­˜è·¯å¾„
        """
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨ fit() æ–¹æ³•")
            
        import pickle
        
        model_data = {
            'params': self.params,
            'scales': self.scales,
            'fit_metrics': self.fit_metrics,
            'param_cov': getattr(self, 'param_cov', None)
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
            
        if self.verbose:
            logger.info(f"Model saved: {filepath}")
    
    def load_model(self, filepath: str):
        """
        ä»æ–‡ä»¶åŠ è½½æ¨¡å‹
        
        Args:
            filepath: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        import pickle
        
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
            
        self.params = model_data['params']
        self.scales = model_data['scales'] 
        self.fit_metrics = model_data['fit_metrics']
        self.param_cov = model_data.get('param_cov')
        self.is_fitted = True
        
        if self.verbose:
            logger.info(f"Model loaded: {filepath}")
            self._print_fit_results()


class StableClusterModel:
    """
    ç¨³å®šçš„é›†ç¾¤è°ƒåº¦æ¨¡å‹
    ä½¿ç”¨ä¸¤é˜¶æ®µæ‹Ÿåˆæ–¹æ³•ï¼š
    1. é¦–å…ˆé€šè¿‡ç®€å•æ–¹æ³•ä¼°è®¡ç¨³å®šçš„P_max
    2. ç„¶åå›ºå®šP_maxï¼Œæ‹Ÿåˆå…¶ä»–å‚æ•°
    """
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self.is_fitted = False
        self.P_max = None  # ç‹¬ç«‹ä¼°è®¡çš„å³°å€¼ååé‡
        self.params = None  # å…¶ä»–æ‹Ÿåˆå‚æ•°
        self.scales = None
        self.fit_metrics = None
        
        # å‚æ•°åç§°ï¼ˆä¸åŒ…æ‹¬P_maxï¼Œå› ä¸ºå®ƒç‹¬ç«‹ä¼°è®¡ï¼‰
        self.param_names = ['k_B', 'k_S', 'tau_B', 'tau_S', 'T_base']
        self.param_descriptions = {
            'P_max': 'ç¡¬ä»¶å³°å€¼ååé‡ (tokens/ms) - ç‹¬ç«‹ä¼°è®¡',
            'k_B': 'batchå¹¶è¡Œåº¦æ•æ„Ÿç³»æ•°',
            'k_S': 'tokenå¹¶è¡Œåº¦æ•æ„Ÿç³»æ•°',
            'tau_B': 'æ¯batchçº¿æ€§å¼€é”€ (ms/batch)',
            'tau_S': 'æ¯tokençº¿æ€§å¼€é”€ (ms/token)',
            'T_base': 'åŸºç¡€å»¶è¿Ÿæ—¶é—´ (ms)'
        }
    
    def _estimate_peak_throughput(self, B: np.ndarray, S: np.ndarray, T: np.ndarray) -> float:
        """
        ç‹¬ç«‹ä¼°è®¡å³°å€¼ååé‡P_max
        ä½¿ç”¨å¤§æ‰¹æ¬¡ã€é«˜tokenæ•°åœºæ™¯ä¸‹çš„æ•°æ®
        """
        # é€‰æ‹©å¤§æ‰¹æ¬¡ã€é«˜tokençš„æ ·æœ¬æ¥ä¼°è®¡å³°å€¼ååé‡
        large_batch_mask = (B >= np.percentile(B, 80)) & (S >= np.percentile(S, 80))
        
        if np.sum(large_batch_mask) < 10:
            # å¦‚æœå¤§æ‰¹æ¬¡æ ·æœ¬å¤ªå°‘ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®
            effective_throughput = S / T
        else:
            # ä½¿ç”¨å¤§æ‰¹æ¬¡æ ·æœ¬
            effective_throughput = S[large_batch_mask] / T[large_batch_mask]
        
        # ä½¿ç”¨90åˆ†ä½æ•°ä½œä¸ºå³°å€¼ååé‡çš„ä¼°è®¡
        P_max_estimate = np.percentile(effective_throughput, 90)
        
        if self.verbose:
            logger.info(f"å³°å€¼ååé‡ä¼°è®¡: {P_max_estimate:.4f} tokens/ms")
            
        return P_max_estimate
    
    @staticmethod
    def stable_latency_model(X: Tuple[np.ndarray, np.ndarray], 
                           k_B: float, k_S: float, tau_B: float, tau_S: float, T_base: float,
                           P_max_fixed: float) -> np.ndarray:
        """
        ç¨³å®šçš„å»¶è¿Ÿæ¨¡å‹ï¼ŒP_maxä½œä¸ºå›ºå®šå‚æ•°ä¼ å…¥
        
        æ¨¡å‹å½¢å¼: T = T_base / (eff_B * eff_S) + tau_B * B + tau_S * S
        å…¶ä¸­ eff_B = (1 - exp(-k_B * B)), eff_S = (1 - exp(-k_S * S))
        T_base åŒ…å«äº† P_max çš„å½±å“ï¼Œä½†é€šè¿‡çº¦æŸå…³ç³»é¿å…å†—ä½™
        """
        B, S = X
        
        # è®¡ç®—å¹¶è¡Œæ•ˆç‡å› å­
        eff_B = 1.0 - np.exp(-k_B * B)
        eff_S = 1.0 - np.exp(-k_S * S)
        
        # é¿å…é™¤é›¶
        eff_B = np.maximum(eff_B, 1e-6)
        eff_S = np.maximum(eff_S, 1e-6)
        
        # å»¶è¿Ÿæ¨¡å‹ï¼šåŸºç¡€å»¶è¿Ÿ/æ•ˆç‡ + çº¿æ€§å¼€é”€
        # T_base ä¸ P_max æœ‰çº¦æŸå…³ç³»ï¼Œä½† P_max å·²å›ºå®š
        latency = T_base / (eff_B * eff_S) + tau_B * B + tau_S * S
        
        return latency
    
    def _extract_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """ä»DataFrameä¸­æå–ç‰¹å¾"""
        def _compute_batch_size(chunk_sizes):
            if isinstance(chunk_sizes, list):
                return len(chunk_sizes)
            return np.nan
            
        def _compute_total_tokens(chunk_sizes):
            if isinstance(chunk_sizes, list) and len(chunk_sizes) > 0:
                return float(sum(chunk_sizes))
            if isinstance(chunk_sizes, (int, float)):
                return float(chunk_sizes)
            return np.nan
        
        B = df['chunk_sizes'].apply(_compute_batch_size).to_numpy(dtype=float)
        S = df['chunk_sizes'].apply(_compute_total_tokens).to_numpy(dtype=float)
        T = df['model_run_duration_ms'].to_numpy(dtype=float)
        
        return B, S, T
    
    def _preprocess_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """æ•°æ®é¢„å¤„ç†"""
        if self.verbose:
            logger.info("å¼€å§‹æ•°æ®é¢„å¤„ç†...")
            
        B, S, T = self._extract_features(df)
        initial_count = len(T)
        
        # æ•°æ®è¿‡æ»¤
        valid_mask = (
            np.isfinite(B) & np.isfinite(S) & np.isfinite(T) &
            (B > 0) & (S > 0) & (T > 0) &
            (T < 300)  # è¿‡æ»¤å¼‚å¸¸å€¼
        )
        
        B, S, T = B[valid_mask], S[valid_mask], T[valid_mask]
        
        if self.verbose:
            logger.info(f"æ•°æ®è¿‡æ»¤: {initial_count} -> {len(T)} æ ·æœ¬")
            logger.info(f"Batch Size èŒƒå›´: [{B.min():.1f}, {B.max():.1f}]")
            logger.info(f"Total Tokens èŒƒå›´: [{S.min():.1f}, {S.max():.1f}]")
            logger.info(f"å»¶è¿ŸèŒƒå›´: [{T.min():.2f}, {T.max():.2f}] ms")
        
        if len(T) < 20:
            raise ValueError(f"æœ‰æ•ˆæ ·æœ¬æ•°è¿‡å°‘: {len(T)}")
            
        return B, S, T
    
    def _normalize_features(self, B: np.ndarray, S: np.ndarray) -> Tuple[np.ndarray, np.ndarray, Tuple[float, float]]:
        """ç‰¹å¾å½’ä¸€åŒ–"""
        B_median = np.median(B)
        S_median = np.median(S)
        
        B_scale = max(B_median, 1.0)
        S_scale = max(S_median, 1.0)
        
        B_norm = B / B_scale
        S_norm = S / S_scale
        
        scales = (B_scale, S_scale)
        
        if self.verbose:
            logger.info(f"ç‰¹å¾å½’ä¸€åŒ–: B_scale={B_scale:.2f}, S_scale={S_scale:.2f}")
            
        return B_norm, S_norm, scales
    
    def fit(self, df: pd.DataFrame) -> 'StableClusterModel':
        """
        ä¸¤é˜¶æ®µæ‹Ÿåˆæ–¹æ³•
        1. ç‹¬ç«‹ä¼°è®¡P_max
        2. å›ºå®šP_maxï¼Œæ‹Ÿåˆå…¶ä»–å‚æ•°
        """
        if self.verbose:
            logger.info("å¼€å§‹ç¨³å®šé›†ç¾¤è°ƒåº¦æ¨¡å‹æ‹Ÿåˆ...")
            
        # æ•°æ®é¢„å¤„ç†
        B, S, T = self._preprocess_data(df)
        B_norm, S_norm, scales = self._normalize_features(B, S)
        self.scales = scales
        
        # é˜¶æ®µ1ï¼šç‹¬ç«‹ä¼°è®¡P_max
        if self.verbose:
            logger.info("é˜¶æ®µ1: ä¼°è®¡å³°å€¼ååé‡...")
        self.P_max = self._estimate_peak_throughput(B_norm, S_norm, T)
        
        # é˜¶æ®µ2ï¼šå›ºå®šP_maxï¼Œæ‹Ÿåˆå…¶ä»–å‚æ•°
        if self.verbose:
            logger.info("é˜¶æ®µ2: æ‹Ÿåˆå…¶ä»–å‚æ•°...")
            
        # åŸºäºP_maxä¼°è®¡åˆå§‹å‚æ•°
        T_median = np.median(T)
        
        p0 = [
            0.5,                # k_B
            0.2,                # k_S  
            1.0,                # tau_B
            0.1,                # tau_S
            T_median * 0.5      # T_base
        ]
        
        # å‚æ•°è¾¹ç•Œ
        lower_bounds = [0.01, 0.001, 0.0, 0.0, 0.1]
        upper_bounds = [5.0, 2.0, 20.0, 2.0, 200.0]
        
        # æ‹Ÿåˆï¼ˆP_maxä½œä¸ºå›ºå®šå‚æ•°ä¼ å…¥ï¼‰
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                
                popt, pcov = curve_fit(
                    lambda X, *params: self.stable_latency_model(X, *params, self.P_max),
                    xdata=(B_norm, S_norm),
                    ydata=T,
                    p0=p0,
                    bounds=(lower_bounds, upper_bounds),
                    maxfev=15000,
                    method='trf'
                )
                
            self.params = popt
            self.param_cov = pcov
            self.is_fitted = True
            
            # è®¡ç®—æ‹Ÿåˆè´¨é‡
            T_pred = self.stable_latency_model((B_norm, S_norm), *popt, self.P_max)
            self.fit_metrics = {
                'r2': r2_score(T, T_pred),
                'rmse': np.sqrt(mean_squared_error(T, T_pred)),
                'mae': mean_absolute_error(T, T_pred),
                'n_samples': len(T)
            }
            
            if self.verbose:
                self._print_fit_results()
                
        except Exception as e:
            logger.error(f"æ‹Ÿåˆå¤±è´¥: {e}")
            raise
            
        return self
    
    def _print_fit_results(self):
        """æ‰“å°æ‹Ÿåˆç»“æœ"""
        logger.info("ç¨³å®šé›†ç¾¤è°ƒåº¦æ¨¡å‹æ‹Ÿåˆå®Œæˆ!")
        logger.info(f"RÂ² = {self.fit_metrics['r2']:.4f}")
        logger.info(f"RMSE = {self.fit_metrics['rmse']:.3f} ms")
        logger.info(f"MAE = {self.fit_metrics['mae']:.3f} ms")
        logger.info(f"æ ·æœ¬æ•° = {self.fit_metrics['n_samples']}")
        
        logger.info("\næ¨¡å‹å‚æ•°:")
        logger.info(f"{'P_max':12s} = {self.P_max:10.6f}  # {self.param_descriptions['P_max']} (ç‹¬ç«‹ä¼°è®¡)")
        
        for i, (name, desc) in enumerate(zip(self.param_names, [self.param_descriptions[name] for name in self.param_names])):
            logger.info(f"{name:12s} = {self.params[i]:10.6f}  # {desc}")
            
        # å‚æ•°ç¨³å®šæ€§åˆ†æ
        try:
            param_std = np.sqrt(np.diag(self.param_cov))
            logger.info("\nå‚æ•°ç¨³å®šæ€§åˆ†æ:")
            logger.info(f"{'P_max':12s} Â± {'N/A':8s} (ç‹¬ç«‹ä¼°è®¡ï¼Œç¨³å®š)")
            
            unstable_count = 0
            for i, name in enumerate(self.param_names):
                if abs(self.params[i]) > 1e-6:
                    relative_error = param_std[i] / abs(self.params[i])
                    if relative_error > 0.5:
                        status = "âš ï¸  ä¸ç¨³å®š"
                        unstable_count += 1
                    elif relative_error > 0.2:
                        status = "âš¡ ä¸­ç­‰"
                    else:
                        status = "âœ… ç¨³å®š"
                    
                    logger.info(f"{name:12s} Â± {param_std[i]:8.6f} (ç›¸å¯¹è¯¯å·®: {relative_error:6.1%}) {status}")
            
            if unstable_count == 0:
                logger.info("ğŸ‰ æ‰€æœ‰å‚æ•°éƒ½ç¨³å®š!")
            else:
                logger.warning(f"âš ï¸  {unstable_count} ä¸ªå‚æ•°ä¸ç¨³å®š")
                
        except Exception as e:
            logger.warning(f"æ— æ³•è®¡ç®—å‚æ•°ç¨³å®šæ€§: {e}")
    
    def predict(self, batch_size: Union[float, np.ndarray], 
                total_tokens: Union[float, np.ndarray]) -> Union[float, np.ndarray]:
        """é¢„æµ‹å»¶è¿Ÿ"""
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªæ‹Ÿåˆ")
            
        B = np.asarray(batch_size)
        S = np.asarray(total_tokens)
        
        # å½’ä¸€åŒ–
        B_scale, S_scale = self.scales
        B_norm = B / B_scale
        S_norm = S / S_scale
        
        # é¢„æµ‹
        latency = self.stable_latency_model((B_norm, S_norm), *self.params, self.P_max)
        
        return latency
    
    def get_hardware_capacity(self) -> Dict[str, float]:
        """è·å–ç¡¬ä»¶èƒ½åŠ›å‚æ•°ï¼Œç”¨äºé›†ç¾¤è°ƒåº¦å†³ç­–"""
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªæ‹Ÿåˆ")
            
        k_B, k_S, tau_B, tau_S, T_base = self.params
        
        # è®¡ç®—ç¡¬ä»¶ç‰¹å¾æŒ‡æ ‡
        batch_50_saturation = -np.log(0.5) / k_B if k_B > 0 else float('inf')
        token_50_saturation = -np.log(0.5) / k_S if k_S > 0 else float('inf')
        
        hardware_info = {
            'peak_throughput_tokens_per_ms': self.P_max,  # å…³é”®è°ƒåº¦å‚æ•° - ç¨³å®šä¼°è®¡
            'batch_efficiency_factor': k_B,
            'token_efficiency_factor': k_S,
            'batch_50_saturation': batch_50_saturation,
            'token_50_saturation': token_50_saturation,
            'per_batch_overhead_ms': tau_B,
            'per_token_overhead_ms': tau_S,
            'base_latency_ms': T_base,
            'hardware_score': self.P_max / (tau_B + tau_S * 100),  # ç»¼åˆæ€§èƒ½è¯„åˆ†
            'estimation_method': 'two_stage_fit'  # æ ‡è®°ä¼°è®¡æ–¹æ³•
        }
        
        return hardware_info
    
    def estimate_optimal_batch_config(self, target_latency_ms: float, 
                                    token_budget: int) -> Dict[str, float]:
        """æ ¹æ®ç›®æ ‡å»¶è¿Ÿä¼°ç®—æœ€ä¼˜æ‰¹æ¬¡é…ç½®"""
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªæ‹Ÿåˆ")
            
        best_config = None
        best_throughput = 0
        
        for batch_size in range(1, 65):
            tokens_per_request = token_budget // batch_size
            if tokens_per_request < 1:
                break
                
            predicted_latency = self.predict(batch_size, token_budget)
            
            if predicted_latency <= target_latency_ms:
                throughput = token_budget / predicted_latency
                if throughput > best_throughput:
                    best_throughput = throughput
                    best_config = {
                        'batch_size': batch_size,
                        'total_tokens': token_budget,
                        'tokens_per_request': tokens_per_request,
                        'predicted_latency_ms': predicted_latency,
                        'effective_throughput': throughput
                    }
        
        return best_config or {
            'batch_size': 1,
            'total_tokens': min(token_budget, 512),
            'tokens_per_request': min(token_budget, 512),
            'predicted_latency_ms': self.predict(1, min(token_budget, 512)),
            'effective_throughput': min(token_budget, 512) / self.predict(1, min(token_budget, 512))
        }
    
    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªæ‹Ÿåˆ")
            
        import pickle
        
        model_data = {
            'P_max': self.P_max,  # ç‹¬ç«‹ä¼°è®¡çš„å³°å€¼ååé‡
            'params': self.params,
            'scales': self.scales,
            'fit_metrics': self.fit_metrics,
            'param_cov': getattr(self, 'param_cov', None),
            'model_type': 'StableClusterModel'
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
            
        if self.verbose:
            logger.info(f"ç¨³å®šé›†ç¾¤è°ƒåº¦æ¨¡å‹å·²ä¿å­˜: {filepath}")
    
    def load_model(self, filepath: str):
        """åŠ è½½æ¨¡å‹"""
        import pickle
        
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
            
        self.P_max = model_data['P_max']
        self.params = model_data['params']
        self.scales = model_data['scales'] 
        self.fit_metrics = model_data['fit_metrics']
        self.param_cov = model_data.get('param_cov')
        self.is_fitted = True
        
        if self.verbose:
            logger.info(f"ç¨³å®šé›†ç¾¤è°ƒåº¦æ¨¡å‹å·²åŠ è½½: {filepath}")


def analyze_model_stability():
    """åˆ†ææ¨¡å‹ç¨³å®šæ€§çš„å·¥å…·å‡½æ•°"""
    print("ğŸ” æ¨¡å‹ç¨³å®šæ€§åˆ†æå»ºè®®")
    print("=" * 50)
    print("å½“å‡ºç°å‚æ•°æ ‡å‡†è¯¯å·®è¿‡å¤§æ—¶ï¼Œå¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š")
    print()
    print("1. å‚æ•°å†—ä½™é—®é¢˜:")
    print("   - åŸå› ï¼šP_max å’Œ w_0 é«˜åº¦ç›¸å…³")
    print("   - è§£å†³ï¼šä½¿ç”¨ StableClusterModel")
    print()
    print("2. è¾¹ç•Œçº¦æŸé—®é¢˜:")
    print("   - åŸå› ï¼šå‚æ•°è¾¾åˆ°ä¸Šä¸‹ç•Œ")
    print("   - è§£å†³ï¼šè°ƒæ•´å‚æ•°è¾¹ç•Œæˆ–é‡æ–°å‚æ•°åŒ–")
    print()
    print("3. æ•°å€¼ç¨³å®šæ€§:")
    print("   - åŸå› ï¼šåæ–¹å·®çŸ©é˜µill-conditioned")
    print("   - è§£å†³ï¼šæ­£åˆ™åŒ–æˆ–é™ç»´")
    print()
    print("4. æ•°æ®è´¨é‡é—®é¢˜:")
    print("   - åŸå› ï¼šå™ªå£°è¿‡å¤§æˆ–æ ·æœ¬åˆ†å¸ƒä¸å‡")
    print("   - è§£å†³ï¼šæ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹")


def demo_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_samples = 1000
    
    # æ¨¡æ‹Ÿçš„batch_sizeså’Œchunk_sizes
    batch_sizes = np.random.randint(1, 33, n_samples)
    chunk_sizes_list = []
    
    for b in batch_sizes:
        # éšæœºç”Ÿæˆæ¯ä¸ªbatchçš„chunk_sizes
        if np.random.random() < 0.3:  # 30% prefill
            sizes = np.random.randint(10, 200, b).tolist()
        else:  # 70% decode  
            sizes = [1] * b
        chunk_sizes_list.append(sizes)
    
    # ä½¿ç”¨çœŸå®æ¨¡å‹ç”Ÿæˆå»¶è¿Ÿï¼ˆåŠ å™ªå£°ï¼‰
    true_params = [50.0, 0.1, 0.02, 5.0, 0.05, 10.0, 0.5, 0.001]
    
    latencies = []
    for i, sizes in enumerate(chunk_sizes_list):
        B = len(sizes)
        S = sum(sizes)
        latency = ThroughputSaturationModel.latency_model((np.array([B]), np.array([S])), *true_params)[0]
        latency += np.random.normal(0, latency * 0.1)  # 10% å™ªå£°
        latencies.append(max(latency, 1.0))  # ç¡®ä¿æ­£å€¼
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame({
        'chunk_sizes': chunk_sizes_list,
        'model_run_duration_ms': latencies,
        'batch_id': range(n_samples)
    })
    
    print("ğŸš€ æ¼”ç¤ºååé¥±å’Œæ¨¡å‹")
    print("=" * 50)
    
    # åˆ›å»ºå¹¶è®­ç»ƒåŸå§‹æ¨¡å‹
    model = ThroughputSaturationModel(verbose=True)
    model.fit(df)
    
    print("\n" + "="*50)
    print("ğŸš€ æ¼”ç¤ºç¨³å®šé›†ç¾¤è°ƒåº¦æ¨¡å‹")
    
    # åˆ›å»ºå¹¶è®­ç»ƒç¨³å®šæ¨¡å‹
    stable_model = StableClusterModel(verbose=True)
    stable_model.fit(df)
    
    # é¢„æµ‹ç¤ºä¾‹
    print(f"\nğŸ“Š é¢„æµ‹å¯¹æ¯”:")
    test_cases = [(8, 512), (16, 256), (32, 128)]
    for B, S in test_cases:
        pred_orig = model.predict(B, S)
        pred_stable = stable_model.predict(B, S)
        print(f"Batch={B:2d}, Tokens={S:3d} -> åŸå§‹: {pred_orig:.2f} ms, ç¨³å®š: {pred_stable:.2f} ms")
    
    # ç¡¬ä»¶èƒ½åŠ›å¯¹æ¯”
    print(f"\nğŸ­ ç¡¬ä»¶èƒ½åŠ›å¯¹æ¯”:")
    print(f"åŸå§‹æ¨¡å‹å³°å€¼ååé‡: {model.params[0]:.4f} tokens/ms")
    hardware_info = stable_model.get_hardware_capacity()
    print(f"ç¨³å®šæ¨¡å‹å³°å€¼ååé‡: {hardware_info['peak_throughput_tokens_per_ms']:.4f} tokens/ms (ç¨³å®šä¼°è®¡)")
    
    # ç»˜åˆ¶ç­‰é«˜çº¿å›¾
    fig1 = model.plot_contour(save_path='./modeling/performance_contour.png')
    
    # ç»˜åˆ¶æ®‹å·®åˆ†æ
    fig2 = model.plot_residuals(df)
    
    plt.show()
    
    return model, stable_model, df


if __name__ == '__main__':
    # è¿è¡Œæ¼”ç¤º
    model, stable_model, df = demo_usage() 
    
    # åˆ†æç¨³å®šæ€§
    analyze_model_stability() 