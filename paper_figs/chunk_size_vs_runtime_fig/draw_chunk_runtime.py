#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç”¨äºç”Ÿæˆ "Chunk Size vs Model Run Time" æ•£ç‚¹å›¾
å®ç°ä»æ•°æ®è¯»å–åˆ°å›¾è¡¨ç”Ÿæˆçš„ç«¯åˆ°ç«¯åŠŸèƒ½
"""

import sys
import os
import json
import numpy as np
import pandas as pd
import argparse
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as mcolors
from pathlib import Path


class ChunkRuntimePlotGenerator:
    """ç”Ÿæˆchunk sizeä¸è¿è¡Œæ—¶é—´å…³ç³»å›¾çš„ç±»"""
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        # æ·»åŠ ä¸çƒ­åŠ›å›¾ç›¸åŒçš„æ ·å¼è®¾ç½®
        self.setup_style()
    
    def setup_style(self):
        """è®¾ç½®matplotlibæ ·å¼ï¼Œä¸çƒ­åŠ›å›¾ä¿æŒä¸€è‡´"""
        plt.rcParams.update({
            'font.size': 12,
            'axes.labelsize': 23,
            'xtick.labelsize': 19,
            'ytick.labelsize': 19,
            'legend.fontsize': 16,
            'figure.figsize': (7, 6),
            'figure.dpi': 300,
            'savefig.dpi': 300,
            'savefig.bbox': 'tight',
            'savefig.pad_inches': 0.1,
            'axes.unicode_minus': False,
        })
    
    def read_profiling_data(self, log_file_or_dir: str) -> pd.DataFrame:
        """è¯»å–profilingæ•°æ®"""
        log_path = Path(log_file_or_dir)
        
        if log_path.is_dir():
            jsonl_files = list(log_path.glob('*.jsonl'))
            if not jsonl_files:
                print(f"âŒ åœ¨ç›®å½• {log_file_or_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°jsonlæ–‡ä»¶")
                return None
            log_files = jsonl_files
            if self.verbose:
                print(f"ğŸ“ æ‰¾åˆ°ç›®å½•: {log_file_or_dir}")
                print(f"ğŸ“„ ä½¿ç”¨æ–‡ä»¶: {len(jsonl_files)} ä¸ª")
        else:
            if not log_path.exists():
                print(f"âŒ æ—¥å¿—æ–‡ä»¶ {log_path} ä¸å­˜åœ¨")
                return None
            log_files = [log_path]
            if self.verbose:
                print(f"ğŸ“„ ä½¿ç”¨å•ä¸ªæ–‡ä»¶: {log_path}")
        
        # è¯»å–æ•°æ®
        data = []
        batch_id_offset = 0
        
        # æ’åºæ–‡ä»¶
        if len(log_files) > 1:
            try:
                log_files.sort(key=lambda x: int(x.stem.split('_')[-1]))
            except Exception:
                log_files.sort(key=lambda x: x.name)
        
        for log_file in log_files:
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                # å»æ‰å‰å10è¡Œ
                for line in lines[10:-10]:
                    try:
                        entry = json.loads(line.strip())
                        if 'batch_id' in entry:
                            entry['batch_id'] += batch_id_offset
                        data.append(entry)
                    except json.JSONDecodeError:
                        continue
            batch_id_offset += len(lines[10:-10])
        
        if not data:
            return None
        
        # æ•°æ®æ¸…æ´—
        data = [item for item in data if item.get('schedule_duration_ms', 0) < 300]
        data = [item for item in data if item.get('model_run_duration_ms', 0) < 200]
        
        df = pd.DataFrame(data)
        
        if self.verbose:
            print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡profilingæ•°æ®")
        
        return df
    
    def generate_chunk_runtime_plot(self, df: pd.DataFrame, save_path: str = None, 
                                   title: str = None) -> plt.Figure:
        """
        ç”Ÿæˆchunk size vs runtimeæ•£ç‚¹å›¾
        
        Args:
            df: åŒ…å«profilingæ•°æ®çš„DataFrame
            save_path: å›¾è¡¨ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            title: å›¾è¡¨æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            matplotlib Figureå¯¹è±¡
        """
        # åˆ›å»ºå›¾è¡¨ï¼Œå‚è€ƒdraw.pyçš„é£æ ¼
        fig, ax = plt.subplots(figsize=(7, 6))
        
        # å¤„ç†chunk_sizesæ•°æ® - è®¡ç®—æ¯ä¸ªæ‰¹æ¬¡çš„æ€»chunk size
        prefill_chunk_totals = df['chunk_sizes'].apply(
            lambda x: sum(x) if isinstance(x, list) else x
        )
        
        # è®¡ç®—batch sizeï¼ˆchunk_sizesçš„é•¿åº¦ï¼‰ï¼Œbatch sizeè¶Šå¤§é¢œè‰²è¶Šæ·±
        batch_sizes = []
        for chunk_sizes in df['chunk_sizes']:
            if isinstance(chunk_sizes, list):
                batch_sizes.append(len(chunk_sizes))
            else:
                batch_sizes.append(1)  # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œé»˜è®¤é•¿åº¦ä¸º1
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ä¾¿äºå¤„ç†
        batch_sizes = np.array(batch_sizes)
        
        # ç»˜åˆ¶æ•£ç‚¹å›¾ï¼Œä½¿ç”¨batch sizeä½œä¸ºé¢œè‰²æ˜ å°„
        # ä½¿ç”¨coolwarmé¢œè‰²æ˜ å°„ï¼šè“è‰²(å°batch size)åˆ°çº¢è‰²(å¤§batch size)
        scatter = ax.scatter(prefill_chunk_totals, df['model_run_duration_ms'], 
                           c=batch_sizes, cmap='coolwarm', alpha=0.8, s=65, 
                           edgecolors='white', linewidth=0.6)
        
        # è®¾ç½®å›¾è¡¨å±æ€§ï¼Œå‚è€ƒdraw.pyçš„é£æ ¼
        ax.set_xlabel('Total Scheduled Tokens', fontsize=23, labelpad=10)
        ax.set_ylabel('Model Run Time (ms)', fontsize=23, labelpad=10)
        
        if title:
            pass
            # ax.set_title(title, fontsize=18, pad=20)
        
        ax.grid(True, linestyle='--', alpha=0.3, linewidth=2)
        
        # è®¾ç½®åæ ‡è½´åˆ»åº¦å­—ä½“å¤§å°
        ax.tick_params(axis='both', pad=8, labelsize=19)
        
        # æ·»åŠ é¢œè‰²æ¡è¯´æ˜batch sizeï¼ˆæ˜¾ç¤ºå®é™…çš„batch sizeèŒƒå›´ï¼‰
        cbar = plt.colorbar(scatter, ax=ax, shrink=0.8, pad=0.02)
        cbar.set_label('Batch Size', fontsize=16, labelpad=5)
        cbar.ax.tick_params(labelsize=14)
        
        # è®¾ç½®é¢œè‰²æ¡åˆ»åº¦ä¸ºæ•´æ•°ï¼ˆbatch sizeé€šå¸¸æ˜¯æ•´æ•°ï¼‰
        if len(np.unique(batch_sizes)) <= 10:  # å¦‚æœbatch sizeç§ç±»ä¸å¤šï¼Œæ˜¾ç¤ºæ‰€æœ‰å€¼
            cbar.set_ticks(np.unique(batch_sizes))
        else:  # å¦‚æœç§ç±»å¾ˆå¤šï¼Œæ˜¾ç¤ºç­‰é—´è·çš„æ•´æ•°åˆ»åº¦
            min_batch = int(batch_sizes.min())
            max_batch = int(batch_sizes.max())
            tick_values = np.linspace(min_batch, max_batch, 8, dtype=int)
            cbar.set_ticks(tick_values)
        
        # è°ƒæ•´å¸ƒå±€ï¼Œä¸çƒ­åŠ›å›¾ä¿æŒä¸€è‡´
        plt.subplots_adjust(left=0.12, right=0.85, bottom=0.15, top=0.92)
        
        # ä¿å­˜å›¾è¡¨ï¼Œä¸çƒ­åŠ›å›¾ä¿æŒä¸€è‡´çš„å‚æ•°
        if save_path:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight', 
                       facecolor='white', edgecolor='none')
            if self.verbose:
                print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
            
            # åŒæ—¶ä¿å­˜PDFæ ¼å¼
            pdf_path = save_path.replace(".png", ".pdf")
            plt.savefig(pdf_path, dpi=300, bbox_inches='tight', format='pdf',
                       facecolor='white', edgecolor='none')
            if self.verbose:
                print(f"ğŸ“Š PDFæ ¼å¼å·²ä¿å­˜è‡³: {pdf_path}")
        
        return fig
    
    def run_end_to_end(self, log_path: str, save_path: str = None, 
                      title: str = None) -> bool:
        """
        è¿è¡Œç«¯åˆ°ç«¯çš„æµç¨‹ï¼šè¯»å–æ•°æ®ã€ç”Ÿæˆå›¾è¡¨
        
        Args:
            log_path: æ—¥å¿—æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
            save_path: å›¾è¡¨ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            title: å›¾è¡¨æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸæ‰§è¡Œ
        """
        try:
            # 1. è¯»å–æ•°æ®
            if self.verbose:
                print("ğŸ“¥ æ­£åœ¨è¯»å–profilingæ•°æ®...")
            
            df = self.read_profiling_data(log_path)
            if df is None or df.empty:
                print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
                return False
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            if 'chunk_sizes' not in df.columns or 'model_run_duration_ms' not in df.columns:
                print("âŒ æ•°æ®ä¸­ç¼ºå°‘å¿…è¦çš„åˆ—: chunk_sizes æˆ– model_run_duration_ms")
                return False
            
            # 2. ç”Ÿæˆå›¾è¡¨
            if self.verbose:
                print("ğŸ“Š æ­£åœ¨ç”ŸæˆChunk Size vs Runtimeå›¾è¡¨...")
            
            self.generate_chunk_runtime_plot(df, save_path=save_path, title=title)
            
            return True
        except Exception as e:
            print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”ŸæˆChunk Size vs Model Run Timeæ•£ç‚¹å›¾')
    parser.add_argument('log_path', type=str, nargs='?', 
                       default='profiling_result',
                       help='profilingæ•°æ®æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ (é»˜è®¤: profiling_result)')
    parser.add_argument('--save-path', type=str, 
                       default="./paper_figs/chunk_size_vs_runtime_fig/chunk_size_vs_runtime.png",
                       help='å›¾è¡¨ä¿å­˜è·¯å¾„')
    parser.add_argument('--title', type=str,
                       help='å›¾è¡¨æ ‡é¢˜')
    parser.add_argument('--verbose', action='store_true', default=True,
                       help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    generator = ChunkRuntimePlotGenerator(verbose=args.verbose)
    
    success = generator.run_end_to_end(
        log_path=args.log_path,
        save_path=args.save_path,
        title=args.title
    )
    
    if success:
        print("âœ… å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
    else:
        print("âŒ å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼")
    
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main() 