#!/usr/bin/env python3
"""
vLLM Scheduler æ—¶é—´è¶‹åŠ¿å›¾ç”Ÿæˆå·¥å…·

è¿™ä¸ªè„šæœ¬ä¸“é—¨ç”¨äºç”Ÿæˆ vLLM scheduler çš„æ—¶é—´è¶‹åŠ¿æ¯”è¾ƒå›¾ï¼ˆTime Trend Comparisonï¼‰ï¼Œ
æ˜¾ç¤ºè°ƒåº¦æ—¶é—´å’Œæ¨¡å‹è¿è¡Œæ—¶é—´éšæ‰¹æ¬¡å˜åŒ–çš„è¶‹åŠ¿ã€‚
"""

import os
import sys
import json
from pathlib import Path
import numpy as np
import argparse
import pandas as pd
import matplotlib.pyplot as plt

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒï¼ˆå¦‚æœéœ€è¦ï¼‰
# plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

def load_and_process_data(log_file_or_dir='scheduler_profiling.jsonl'):
    """åŠ è½½å¹¶å¤„ç†profilingæ•°æ®"""
    log_path = Path(log_file_or_dir)
    
    # å¦‚æœæ˜¯ç›®å½•ï¼ŒæŸ¥æ‰¾å…¶ä¸­çš„jsonlæ–‡ä»¶
    if log_path.is_dir():
        jsonl_files = list(log_path.glob('*.jsonl'))
        if not jsonl_files:
            print(f"âŒ åœ¨ç›®å½• {log_file_or_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°jsonlæ–‡ä»¶")
            return None
        # ä½¿ç”¨å…¨éƒ¨jsonlæ–‡ä»¶
        log_files = jsonl_files
        print(f"ğŸ“ æ‰¾åˆ°ç›®å½•: {log_file_or_dir}")
        print(f"ğŸ“„ ä½¿ç”¨æ–‡ä»¶: {len(jsonl_files)} ä¸ª")
    else:
        log_file = log_path
        if not log_file.exists():
            print(f"âŒ æ—¥å¿—æ–‡ä»¶ {log_file} ä¸å­˜åœ¨")
            return None
        # å•æ–‡ä»¶åˆ†æ
        log_files = [log_file]
        print(f"ğŸ“„ ä½¿ç”¨å•ä¸ªæ–‡ä»¶: {log_file}")
    
    # è¯»å–æ•°æ®
    data = []
    batch_id_offset = 0
    # æ ¹æ®æ–‡ä»¶åä¸­çš„æ•°å­—æ’åºï¼›è‹¥åªæœ‰ä¸€ä¸ªæ–‡ä»¶æˆ–è§£æå¤±è´¥åˆ™æŒ‰åç§°æ’åº/ä¿æŒä¸å˜
    if len(log_files) > 1:
        try:
            log_files.sort(key=lambda x: int(x.stem.split('_')[-1]))
        except Exception:
            log_files.sort(key=lambda x: x.name)
    
    for log_file in log_files:
        with open(log_file, 'r', encoding='utf-8') as f:
            # å»æ‰æ¯ä¸ªæ–‡ä»¶çš„å‰10è¡Œå’Œå10è¡Œï¼Œé¿å…æ–‡ä»¶å¼€å¤´å’Œç»“å°¾å¯èƒ½çš„éJSONå†…å®¹
            lines = f.readlines()
            for line in lines[10:-10]:
                try:
                    entry = json.loads(line.strip())
                    # å¯¹batch idè¿›è¡Œé‡æ–°å¤„ç†ï¼Œç¡®ä¿è¿ç»­æ€§
                    if 'batch_id' in entry:
                        entry['batch_id'] += batch_id_offset
                    data.append(entry)
                except json.JSONDecodeError:
                    continue
        batch_id_offset += len(lines[10:-10])

    # æ•°æ®æ¸…æ´—
    # å°†è°ƒåº¦æ—¶é—´åœ¨300msä»¥ä¸Šçš„æ•°æ®åˆ é™¤ï¼Œè¿‡æ»¤å¼‚å¸¸å€¼
    data = [item for item in data if item['schedule_duration_ms'] < 300]
    # å°†è¿è¡Œæ—¶é—´åœ¨200msä»¥ä¸Šçš„æ•°æ®åˆ é™¤ï¼Œè¿‡æ»¤å¼‚å¸¸å€¼
    data = [item for item in data if item['model_run_duration_ms'] < 200]
    
    if not data:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„profilingæ•°æ®")
        return None
    
    df = pd.DataFrame(data)
    print(f"âœ… æˆåŠŸè¯»å– {len(data)} æ¡profilingæ•°æ®")
    
    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š Scheduler æ—¶é—´ç»Ÿè®¡")
    print("=" * 50)
    print(f"â±ï¸  å¹³å‡è°ƒåº¦æ—¶é—´: {df['schedule_duration_ms'].mean():.2f}ms")
    print(f"â±ï¸  æœ€å¤§è°ƒåº¦æ—¶é—´: {df['schedule_duration_ms'].max():.2f}ms")
    print(f"â±ï¸  æœ€å°è°ƒåº¦æ—¶é—´: {df['schedule_duration_ms'].min():.2f}ms")
    
    if 'model_run_duration_ms' in df.columns:
        print(f"âš¡ å¹³å‡Model Runæ—¶é—´: {df['model_run_duration_ms'].mean():.2f}ms")
        print(f"âš¡ æœ€å¤§Model Runæ—¶é—´: {df['model_run_duration_ms'].max():.2f}ms")
        print(f"âš¡ æœ€å°Model Runæ—¶é—´: {df['model_run_duration_ms'].min():.2f}ms")
    
    print(f"ğŸ”¢ å¹³å‡æ€»Tokenæ•°: {df['total_scheduled_tokens'].mean():.2f}")
    
    return df

def create_time_trend_plot(df, output_file='./time_trend_comparison.png'):
    """åˆ›å»ºæ—¶é—´è¶‹åŠ¿æ¯”è¾ƒå›¾ï¼Œé€‚åˆå­¦æœ¯è®ºæ–‡"""
    
    # å­¦æœ¯è®ºæ–‡é…è‰²æ–¹æ¡ˆ
    COLORS = ['#2E3440', '#5E81AC', '#A3BE8C', '#EBCB8B']
    LINE_STYLES = ['-', '--', '-.', ':']
    
    # æ£€æŸ¥æ•°æ®
    has_model_run_data = 'model_run_duration_ms' in df.columns
    
    # åˆ›å»ºé€‚åˆè®ºæ–‡çš„å›¾è¡¨å°ºå¯¸
    fig, ax = plt.subplots(figsize=(3.5, 3), dpi=300)
    
    # ç»˜åˆ¶æ•°æ®
    if has_model_run_data:
        ax.plot(df['batch_id'], df['schedule_duration_ms'], 
               label='Schedule Time', color=COLORS[0], 
               linestyle=LINE_STYLES[0], linewidth=1.5, alpha=0.9)
        ax.plot(df['batch_id'], df['model_run_duration_ms'], 
               label='Model Execution Time', color=COLORS[1], 
               linestyle=LINE_STYLES[1], linewidth=1.5, alpha=0.9)
    
    # è®¾ç½®åæ ‡è½´æ ‡ç­¾
    ax.set_xlabel('Batch ID', fontsize=12, labelpad=2)
    ax.set_ylabel('Latency (ms)', fontsize=12, labelpad=2)
    
    # è®¾ç½®åˆ»åº¦
    ax.tick_params(axis='both', which='major', labelsize=9, pad=2)
    
    # ä¼˜åŒ–ç½‘æ ¼çº¿
    ax.grid(True, which='major', linestyle=':', alpha=0.4, 
            color='#D8DEE9', linewidth=0.5)
    
    # å›¾ä¾‹è®¾ç½®
    if has_model_run_data:
        ax.legend(loc='upper left', frameon=True, fancybox=False, 
                 framealpha=0.9, edgecolor='black', fontsize=9,
                 borderpad=0.3, labelspacing=0.3)
    
    # ç´§å‡‘å¸ƒå±€
    plt.subplots_adjust(left=0.12, right=0.95, bottom=0.15, top=0.9)
    
    # ä¿å­˜é«˜è´¨é‡ç‰ˆæœ¬
    plt.savefig(output_file, dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    pdf_path = "paper_figs/scheduling_overhead_fig/scheduling_overhead.pdf"
    plt.savefig(pdf_path, dpi=300, bbox_inches='tight', 
                format='pdf', facecolor='white')
    
    print(f"ğŸ“Š å­¦æœ¯é£æ ¼å›¾è¡¨å·²ä¿å­˜: {output_file}")

def main():
    
    print("ğŸš€ vLLM Scheduler æ—¶é—´è¶‹åŠ¿å›¾ç”Ÿæˆå·¥å…·")
    print("=" * 40)

    log_dir = "exp"
    parser = argparse.ArgumentParser(description='ç”Ÿæˆ Schedule Overhead å›¾è¡¨')
    parser.add_argument('log_path', type=str, nargs='*',default=f"{log_dir}/profiling_result_h100_qwen32b",
                      help='profilingæ•°æ®æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ (å¯æŒ‡å®šå¤šä¸ªï¼Œé»˜è®¤: profiling_result)')
    parser.add_argument('--save-path', type=str, default="paper_figs/scheduling_overhead_fig/sechdule_overhead.png")
    
    args = parser.parse_args()
    
    log_path = args.log_path
    output_file = args.save_path
    
    # åŠ è½½å’Œå¤„ç†æ•°æ®
    df = load_and_process_data(log_path)
    if df is None:
        return
    
    # åˆ›å»ºå¹¶ä¿å­˜æ—¶é—´è¶‹åŠ¿å›¾ï¼Œä¼ å…¥æ¨¡æ‹Ÿæ•°æ®å‚æ•°å’Œå¯†åº¦å› å­
    create_time_trend_plot(df, output_file)
    
    print("\nâœ… å¤„ç†å®Œæˆ!")

if __name__ == '__main__':
    main()