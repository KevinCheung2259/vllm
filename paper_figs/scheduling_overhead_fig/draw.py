#!/usr/bin/env python3
"""
vLLM Scheduler æ—¶é—´è¶‹åŠ¿å›¾ç”Ÿæˆå·¥å…·

è¿™ä¸ªè„šæœ¬ä¸“é—¨ç”¨äºç”Ÿæˆ vLLM scheduler çš„æ—¶é—´è¶‹åŠ¿æ¯”è¾ƒå›¾ï¼ˆTime Trend Comparisonï¼‰ï¼Œ
æ˜¾ç¤ºè°ƒåº¦æ—¶é—´å’Œæ¨¡å‹è¿è¡Œæ—¶é—´éšæ‰¹æ¬¡å˜åŒ–çš„è¶‹åŠ¿ã€‚
"""

import os
import sys
import json
from pathlib import Path
import numpy as np
import argparse
import pandas as pd
import matplotlib.pyplot as plt

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒï¼ˆå¦‚æœéœ€è¦ï¼‰
# plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

def load_and_process_data(log_file_or_dir='scheduler_profiling.jsonl'):
    """åŠ è½½å¹¶å¤„ç†profilingæ•°æ®"""
    log_path = Path(log_file_or_dir)
    
    # å¦‚æœæ˜¯ç›®å½•ï¼ŒæŸ¥æ‰¾å…¶ä¸­çš„jsonlæ–‡ä»¶
    if log_path.is_dir():
        jsonl_files = list(log_path.glob('*.jsonl'))
        if not jsonl_files:
            print(f"âŒ åœ¨ç›®å½• {log_file_or_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°jsonlæ–‡ä»¶")
            return None
        # ä½¿ç”¨å…¨éƒ¨jsonlæ–‡ä»¶
        log_files = jsonl_files
        print(f"ğŸ“ æ‰¾åˆ°ç›®å½•: {log_file_or_dir}")
        print(f"ğŸ“„ ä½¿ç”¨æ–‡ä»¶: {len(jsonl_files)} ä¸ª")
    else:
        log_file = log_path
        if not log_file.exists():
            print(f"âŒ æ—¥å¿—æ–‡ä»¶ {log_file} ä¸å­˜åœ¨")
            return None
        # å•æ–‡ä»¶åˆ†æ
        log_files = [log_file]
        print(f"ğŸ“„ ä½¿ç”¨å•ä¸ªæ–‡ä»¶: {log_file}")
    
    # è¯»å–æ•°æ®
    data = []
    batch_id_offset = 0
    # æ ¹æ®æ–‡ä»¶åä¸­çš„æ•°å­—æ’åºï¼›è‹¥åªæœ‰ä¸€ä¸ªæ–‡ä»¶æˆ–è§£æå¤±è´¥åˆ™æŒ‰åç§°æ’åº/ä¿æŒä¸å˜
    if len(log_files) > 1:
        try:
            log_files.sort(key=lambda x: int(x.stem.split('_')[-1]))
        except Exception:
            log_files.sort(key=lambda x: x.name)
    
    for log_file in log_files:
        with open(log_file, 'r', encoding='utf-8') as f:
            # å»æ‰æ¯ä¸ªæ–‡ä»¶çš„å‰10è¡Œå’Œå10è¡Œï¼Œé¿å…æ–‡ä»¶å¼€å¤´å’Œç»“å°¾å¯èƒ½çš„éJSONå†…å®¹
            lines = f.readlines()
            for line in lines[10:-10]:
                try:
                    entry = json.loads(line.strip())
                    # å¯¹batch idè¿›è¡Œé‡æ–°å¤„ç†ï¼Œç¡®ä¿è¿ç»­æ€§
                    if 'batch_id' in entry:
                        entry['batch_id'] += batch_id_offset
                    data.append(entry)
                except json.JSONDecodeError:
                    continue
        batch_id_offset += len(lines[10:-10])

    # æ•°æ®æ¸…æ´—
    # å°†è°ƒåº¦æ—¶é—´åœ¨300msä»¥ä¸Šçš„æ•°æ®åˆ é™¤ï¼Œè¿‡æ»¤å¼‚å¸¸å€¼
    data = [item for item in data if item['schedule_duration_ms'] < 300]
    # å°†è¿è¡Œæ—¶é—´åœ¨200msä»¥ä¸Šçš„æ•°æ®åˆ é™¤ï¼Œè¿‡æ»¤å¼‚å¸¸å€¼
    data = [item for item in data if item['model_run_duration_ms'] < 200]
    
    if not data:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„profilingæ•°æ®")
        return None
    
    df = pd.DataFrame(data)
    print(f"âœ… æˆåŠŸè¯»å– {len(data)} æ¡profilingæ•°æ®")
    
    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š Scheduler æ—¶é—´ç»Ÿè®¡")
    print("=" * 50)
    print(f"â±ï¸  å¹³å‡è°ƒåº¦æ—¶é—´: {df['schedule_duration_ms'].mean():.2f}ms")
    print(f"â±ï¸  æœ€å¤§è°ƒåº¦æ—¶é—´: {df['schedule_duration_ms'].max():.2f}ms")
    print(f"â±ï¸  æœ€å°è°ƒåº¦æ—¶é—´: {df['schedule_duration_ms'].min():.2f}ms")
    
    if 'model_run_duration_ms' in df.columns:
        print(f"âš¡ å¹³å‡Model Runæ—¶é—´: {df['model_run_duration_ms'].mean():.2f}ms")
        print(f"âš¡ æœ€å¤§Model Runæ—¶é—´: {df['model_run_duration_ms'].max():.2f}ms")
        print(f"âš¡ æœ€å°Model Runæ—¶é—´: {df['model_run_duration_ms'].min():.2f}ms")
    
    print(f"ğŸ”¢ å¹³å‡æ€»Tokenæ•°: {df['total_scheduled_tokens'].mean():.2f}")
    
    return df

def create_time_trend_plot(df, output_file='./time_trend_comparison.png'):

    """åˆ›å»ºæ—¶é—´è¶‹åŠ¿æ¯”è¾ƒå›¾ï¼Œæ”¯æŒæ·»åŠ æ¨¡æ‹Ÿæ•°æ®"""
    # æ£€æŸ¥æ˜¯å¦æœ‰model runæ—¶é—´æ•°æ®
    has_model_run_data = 'model_run_duration_ms' in df.columns
    
    # åˆ›å»ºå›¾è¡¨
    fig, ax = plt.subplots(figsize=(7, 6))
    
    # ç»˜åˆ¶æ—¶é—´è¶‹åŠ¿
    if has_model_run_data:
        ax.plot(df['batch_id'], df['schedule_duration_ms'], label='Engine schedule Time', alpha=0.7)
        ax.plot(df['batch_id'], df['model_run_duration_ms'], label='Model Run Time', alpha=0.7)
        # è®¡ç®—æ€»æ—¶é—´å¹¶ç»˜åˆ¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # total_time = df['schedule_duration_ms'] + df['model_run_duration_ms']
        # ax.plot(df['batch_id'], total_time, label='Total Time', alpha=0.7)
        ## æ ‡é¢˜
        # ax.set_title('Time Trend Comparison')
    else:
        ax.plot(df['batch_id'], df['schedule_duration_ms'], label='Engine schedule Time')
        ax.set_title('Schedule Time Trend')
    
    # æ·»åŠ å›¾ä¾‹ï¼ˆå¦‚æœæœ‰å¤šä¸ªæ•°æ®ç³»åˆ—ï¼‰
    if has_model_run_data or (sim_mean is not None and sim_variance is not None):
        ax.legend(fontsize = 12,markerscale=1.1)
    
    # è®¾ç½®åæ ‡è½´æ ‡ç­¾å’Œç½‘æ ¼
    ax.set_xlabel('Batch ID',fontsize=16,labelpad=10)
    ax.set_ylabel('Time (ms)',fontsize=16,labelpad=10)
    # è®¾ç½®åæ ‡è½´åˆ»åº¦å­—ä½“å¤§å°
    ax.tick_params(axis='both', pad=8, labelsize=12)  
    ax.grid(True, linestyle='--', alpha=0.3)
    plt.subplots_adjust(left=0.15, right=0.8, bottom=0.15, top=0.8)
    # ç¾åŒ–å›¾è¡¨
    plt.tight_layout()
    pdf_path = "./sechdule_overhead.pdf"
    # ä¿å­˜å›¾è¡¨
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.savefig(pdf_path, dpi=300, bbox_inches='tight', format='pdf')
    print(f"\nğŸ“Š æ—¶é—´è¶‹åŠ¿å›¾å·²ä¿å­˜ä¸º: {output_file}")
    
    # æ˜¾ç¤ºå›¾è¡¨ï¼ˆå¦‚æœåœ¨äº¤äº’ç¯å¢ƒä¸­è¿è¡Œï¼‰
    # plt.show()

def main():
    
    print("ğŸš€ vLLM Scheduler æ—¶é—´è¶‹åŠ¿å›¾ç”Ÿæˆå·¥å…·")
    print("=" * 40)

    log_dir = "./../../exp"
    parser = argparse.ArgumentParser(description='ç”Ÿæˆ Schedule Overhead å›¾è¡¨')
    parser.add_argument('log_path', type=str, nargs='*',default=f"{log_dir}/profiling_result_a100",
                      help='profilingæ•°æ®æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ (å¯æŒ‡å®šå¤šä¸ªï¼Œé»˜è®¤: profiling_result)')
    parser.add_argument('--save-path', type=str, default="./sechdule_overhead.png")
    
    args = parser.parse_args()
    
    log_path = args.log_path
    output_file = args.save_path
    
    # åŠ è½½å’Œå¤„ç†æ•°æ®
    df = load_and_process_data(log_path)
    if df is None:
        return
    
    # åˆ›å»ºå¹¶ä¿å­˜æ—¶é—´è¶‹åŠ¿å›¾ï¼Œä¼ å…¥æ¨¡æ‹Ÿæ•°æ®å‚æ•°å’Œå¯†åº¦å› å­
    create_time_trend_plot(df, output_file)
    
    print("\nâœ… å¤„ç†å®Œæˆ!")

if __name__ == '__main__':
    main()